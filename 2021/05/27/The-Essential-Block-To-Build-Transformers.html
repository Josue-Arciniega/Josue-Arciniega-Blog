<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>It’s time, now we can put blocks together to build a Transformer | Josue Arciniega’s Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="It’s time, now we can put blocks together to build a Transformer" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Just a blog." />
<meta property="og:description" content="Just a blog." />
<link rel="canonical" href="https://josue-arciniega.github.io/Josue-Arciniega-Blog/2021/05/27/The-Essential-Block-To-Build-Transformers.html" />
<meta property="og:url" content="https://josue-arciniega.github.io/Josue-Arciniega-Blog/2021/05/27/The-Essential-Block-To-Build-Transformers.html" />
<meta property="og:site_name" content="Josue Arciniega’s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-27T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://josue-arciniega.github.io/Josue-Arciniega-Blog/2021/05/27/The-Essential-Block-To-Build-Transformers.html","@type":"BlogPosting","headline":"It’s time, now we can put blocks together to build a Transformer","dateModified":"2021-05-27T00:00:00-05:00","datePublished":"2021-05-27T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://josue-arciniega.github.io/Josue-Arciniega-Blog/2021/05/27/The-Essential-Block-To-Build-Transformers.html"},"description":"Just a blog.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Josue-Arciniega-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://josue-arciniega.github.io/Josue-Arciniega-Blog/feed.xml" title="Josue Arciniega's Blog" /><link rel="shortcut icon" type="image/x-icon" href="/Josue-Arciniega-Blog/images/logo.png">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Josue-Arciniega-Blog/">Josue Arciniega&#39;s Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Josue-Arciniega-Blog/about/">About Me</a><a class="page-link" href="/Josue-Arciniega-Blog/search/">Search</a><a class="page-link" href="/Josue-Arciniega-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">It&#39;s time, now we can put blocks together to build a Transformer</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-05-27T00:00:00-05:00" itemprop="datePublished">
        May 27, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/Josue-Arciniega/Josue-Arciniega-Blog/tree/master/_notebooks/2021-05-27-The-Essential-Block-To-Build-Transformers.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Josue-Arciniega-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/Josue-Arciniega/Josue-Arciniega-Blog/master?filepath=_notebooks%2F2021-05-27-The-Essential-Block-To-Build-Transformers.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Josue-Arciniega-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/Josue-Arciniega/Josue-Arciniega-Blog/blob/master/_notebooks/2021-05-27-The-Essential-Block-To-Build-Transformers.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Josue-Arciniega-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-05-27-The-Essential-Block-To-Build-Transformers.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A transformer is a architecture that is based on the paper that i've been mentioning Attention Is All You Need so, let's try to implement it</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Defining-a-transformer-block">Defining a transformer block<a class="anchor-link" href="#Defining-a-transformer-block"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>in order to use transformers in larger networks, it make sense to build a transformer block, so we can call it every time we need it, the structure we'll use is the most comon i think, it consists of a self-attention layer, then a normalization layer (over the embedding dimmension), a feed forwrd (a multilayer perceptron for each vector) and then another normalization layer, we will use residual connections before each normalization layer by now, maybe we'll change the order in next posts.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="k">class</span> <span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="o">=</span><span class="n">SelfAttentionWithTricks</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="mi">5</span><span class="o">*</span><span class="n">k</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
        <span class="n">attended</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">attended</span><span class="o">+</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">feededforward</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">feededforward</span><span class="o">+</span><span class="n">x</span><span class="p">)</span>
    
    
    
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And that's it, we've made the transformer block, so, we can start building our transformer architectures.
In next post's we'll use the code we've been writing to train an architecture for different porpouses.
Note that for the linear transform we've chosen 5 times the input dimmention, this is kind of a  hyper-parameter  we can use to modify the learning process, it can be another multiple of input/output.
it could be interensting, to try implementing a droput layer, but, it is for another post</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/Josue-Arciniega-Blog/2021/05/27/The-Essential-Block-To-Build-Transformers.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Josue-Arciniega-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Josue-Arciniega-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Josue-Arciniega-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Just a blog.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Josue-Arciniega" title="Josue-Arciniega"><svg class="svg-icon grey"><use xlink:href="/Josue-Arciniega-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/JosueArciniegaN" title="JosueArciniegaN"><svg class="svg-icon grey"><use xlink:href="/Josue-Arciniega-Blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
